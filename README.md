# Classificador de Chamados de Clientes (NLP)

Este projeto foi desenvolvido como trabalho final da disciplina de Processamento de Linguagem Natural (NLP) do MBA em Data Science & AI.

O objetivo √© construir um *pipeline* de Machine Learning para classificar automaticamente chamados de clientes (textos) em 5 categorias de atendimento, otimizando o processo de triagem.

## üöÄ Metodologia e Pipeline

O projeto seguiu um pipeline completo de NLP:

1.  **Prepara√ß√£o dos Dados:** O dataset (`chamados.csv`) foi carregado e limpo (remo√ß√£o de nulos).
2.  **Pr√©-processamento de Texto:** Foi criada uma fun√ß√£o de limpeza usando **NLTK** e **Regex** para converter o texto para min√∫sculas, remover pontua√ß√µes e *stopwords* em portugu√™s.
3.  **Divis√£o:** O dataset foi dividido em 75% para treino e 25% para teste (`random_state=42`, `stratify=y`).
4.  **Engenharia de Features (Vetoriza√ß√£o):** Foram testadas e comparadas duas abordagens principais:
    * **TF-IDF:** Usando `TfidfVectorizer` (com unigramas + bigramas).
    * **Word Embeddings:** Usando `Word2Vec` (Gensim) com a m√©dia dos vetores de palavras.
5.  **Modelagem e Avalia√ß√£o:** M√∫ltiplos classificadores supervisionados foram treinados e avaliados pela sua Acur√°cia e F1-Score.

## üìä Resultados e Compara√ß√£o

O modelo de **Regress√£o Log√≠stica** combinado com a vetoriza√ß√£o **TF-IDF (Uni+Bigramas)** foi o grande vencedor, superando significativamente os outros *baselines*.

| Modelo | Vetoriza√ß√£o | Acur√°cia | F1-Score (Ponderado) |
| :--- | :--- | :--- | :--- |
| **Regress√£o Log√≠stica (Vencedor)** | **TF-IDF (Uni+Bigramas)** | **90.6%** | **0.91** |
| RandomForest | Word2Vec (M√©dia) | 82.0% | 0.81 |
| Multinomial Naive Bayes (Baseline) | TF-IDF (Uni+Bigramas) | 74.5% | 0.71 |

O Naive Bayes se mostrou ineficaz (F1 de 0.09) para a classe "Outros", enquanto a Regress√£o Log√≠stica manteve alta performance em todas as categorias.

## üõ†Ô∏è Tecnologias Utilizadas

* **Python**
* **Pandas:** Para manipula√ß√£o de dados.
* **Scikit-learn:** Para `train_test_split`, `TfidfVectorizer`, `LogisticRegression`, `MultinomialNB` e m√©tricas de avalia√ß√£o.
* **NLTK:** Para pr√©-processamento e remo√ß√£o de *stopwords*.
* **Gensim:** Para o treinamento do modelo `Word2Vec`.
* **Matplotlib / Seaborn:** Para visualiza√ß√£o de dados.

## üèÅ Como Executar

1.  Clone este reposit√≥rio.
2.  Instale as depend√™ncias (ex: `pip install pandas scikit-learn nltk gensim matplotlib seaborn`).
3.  Abra e execute o notebook Jupyter `Template_Trabalho_Final_NLP.ipynb` em um ambiente como o Google Colab.
